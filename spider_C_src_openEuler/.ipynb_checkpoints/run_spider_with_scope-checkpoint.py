import time
import subprocess
import random
import pandas as pd


# 源文件路径和目标文件路径
source_file = '../../spider_Gitee_repoInfo/spider_repo/spider_repo/C++_Repo.csv'

scope = [i for i in range(4, 14)]


df = pd.read_csv(source_file)  # step1得到的

# urls = [df.iloc[i]['repoLink']+"/commits/master" for i in range(len(df))] openeuler
urls = ['https://gitee.com' + link + "/commits/master" for link in df['repo_url'].tolist()[80:85]] # other

for url in urls:
    print("starting..........  ", url)
    subprocess.run(['scrapy', 'crawl', 'C_openEuler_Bykey', '-a', f'start_url={url}', '-o', 'otherC++RepoInfo1.csv'])
    sleep_time = random.choice(scope)
    print("接下来会休眠: ", sleep_time, "s")
    time.sleep(sleep_time)

#df = pd.read_csv('patchsInfo.csv')
#idx = df[df['commit_url'] == 'commit_url'].index
#print(idx)
#df_process = df.drop(index=idx)   # 删除重复的列名字
#df_process.to_csv('patchsInfo.csv', index=False)